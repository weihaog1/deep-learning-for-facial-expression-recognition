Create a professional, visually appealing presentation for a university machine learning course (COMPSCI 178) on the following project:

================================================================================
PROJECT TITLE
================================================================================
Deep Learning for Facial Expression Recognition in Uncontrolled Environments

================================================================================
COURSE CONTEXT
================================================================================
- Course: COMPSCI 178 - Machine Learning and Data Mining
- Project Type: Comparative study of traditional ML vs deep learning approaches
- Focus: Emotion classification from facial images

================================================================================
PRESENTATION STRUCTURE (Suggested 12-15 slides)
================================================================================

SLIDE 1: Title Slide
- Project title: "Deep Learning for Facial Expression Recognition"
- Subtitle: "Comparing Traditional ML and Deep Learning Approaches"
- Course: COMPSCI 178
- Team members: [Leave placeholder for names]
- Date: [Current date]
- Use a professional, clean design with a subtle image of diverse facial expressions

SLIDE 2: Problem Statement & Motivation
- Facial Expression Recognition (FER) is critical for human-computer interaction
- Applications: customer satisfaction analysis, driver alertness monitoring, healthcare
- Challenge: Models trained on lab conditions fail in real-world "in-the-wild" scenarios
- Our goal: Build a robust emotion classifier that works on uncontrolled images
- Include a visual showing the difference between controlled vs uncontrolled images

SLIDE 3: Dataset Overview
- Dataset: Muxspace Facial Expression Dataset
- Size: ~13,700 labeled face images
- 7 emotion classes: Anger, Disgust, Fear, Happiness, Neutral, Sadness, Surprise
- Key challenge: Significant class imbalance
- Show a pie chart or bar graph with class distribution:
  * Neutral: 6,868 (50.2%)
  * Happiness: 5,696 (41.6%)
  * Surprise: 368 (2.7%)
  * Sadness: 268 (2.0%)
  * Anger: 252 (1.8%)
  * Disgust: 208 (1.5%)
  * Fear: 21 (0.2%)
- Include sample images from each emotion class

SLIDE 4: Methodology Overview
- Show a flowchart of our approach:
  1. Data Preprocessing → 2. Feature Extraction/Model → 3. Training → 4. Evaluation
- Three models compared:
  * Baseline: HOG + SVM (Traditional ML)
  * Custom CNN (Deep Learning from scratch)
  * Transfer Learning with ResNet18 (Pretrained Deep Learning)
- Mention data augmentation techniques used

SLIDE 5: Data Preprocessing & Augmentation
- Preprocessing steps:
  * Face detection and cropping
  * Resize to 224x224 (CNN) or 48x48 (baseline)
  * Normalization with ImageNet statistics
- Data augmentation (training only):
  * Random horizontal flip (faces are symmetric)
  * Random rotation (±10 degrees)
  * Color jitter (brightness/contrast)
- Purpose: Combat limited dataset size, prevent overfitting
- Show before/after augmentation examples

SLIDE 6: Baseline Model - HOG + SVM
- HOG (Histogram of Oriented Gradients):
  * Captures edge directions and gradients
  * Hand-crafted features (not learned)
  * Feature vector size: 900 dimensions
- SVM (Support Vector Machine):
  * RBF kernel for non-linear classification
  * Class weighting to handle imbalance
- Show a visualization of HOG features on a face
- Purpose: Establish performance baseline for comparison

SLIDE 7: Custom CNN Architecture
- Architecture diagram showing:
  * Input: 224x224x3 RGB image
  * 4 Convolutional Blocks (Conv → BatchNorm → ReLU → MaxPool)
  * Channels: 32 → 64 → 128 → 256
  * Global Average Pooling
  * Fully Connected: 256 → 128 → 7 classes
  * Dropout (0.5) for regularization
- Total parameters: ~1.2 million
- Key design choices: BatchNorm for stability, GAP to reduce overfitting

SLIDE 8: Transfer Learning with ResNet18
- What is Transfer Learning?
  * Use model pretrained on ImageNet (1.2M images, 1000 classes)
  * Pretrained features transfer well to new tasks
- Our approach - Two-phase training:
  * Phase 1: Freeze backbone, train only classifier (fast)
  * Phase 2: Unfreeze, fine-tune entire network with low learning rate
- Why ResNet18?
  * Residual connections prevent vanishing gradients
  * Good balance of accuracy and efficiency
  * Pretrained weights capture rich visual features

SLIDE 9: Training Details
- Training configuration:
  * Optimizer: Adam
  * Loss: Cross-Entropy
  * Batch size: 32
  * Learning rate: 0.001 (0.0001 for fine-tuning)
- Techniques used:
  * Early stopping (patience=5 epochs)
  * Learning rate scheduling (reduce on plateau)
  * Stratified train/val/test split (70%/10%/20%)
- Show training curves (loss and accuracy over epochs)

SLIDE 10: Results Comparison
- Create a prominent comparison table:
  | Model               | Test Accuracy |
  |---------------------|---------------|
  | HOG + SVM (Baseline)| 82.1%         |
  | Custom CNN          | XX.X%         |
  | ResNet18 (Transfer) | XX.X%         |
- Key finding: Transfer learning outperforms training from scratch
- Deep learning beats traditional ML
- Show bar chart comparing the three models

SLIDE 11: Per-Class Performance Analysis
- Show confusion matrices for each model (or best model)
- Highlight common misclassifications:
  * Fear often confused with surprise (similar wide eyes)
  * Sadness confused with neutral
  * Disgust confused with anger
- Per-class F1 scores:
  * Easiest: Happiness, Neutral (most data)
  * Hardest: Fear, Disgust (least data)
- Discuss impact of class imbalance on results

SLIDE 12: Model Interpretability - Grad-CAM
- What is Grad-CAM?
  * Visualizes which image regions the model focuses on
  * Gradient-weighted Class Activation Mapping
- Show Grad-CAM heatmap examples:
  * Happiness: Focus on mouth/smile
  * Anger: Focus on eyebrows/eyes
  * Surprise: Focus on wide eyes and open mouth
- Key insight: Model correctly learns to focus on facial features, not background
- Important for trust and debugging

SLIDE 13: Key Insights & Lessons Learned
- Transfer learning is powerful for limited data
- Class imbalance significantly hurts minority class performance
- Data augmentation is essential for small datasets
- Deep learning automates feature learning (vs hand-crafted HOG)
- Grad-CAM confirms model learns meaningful patterns
- Real-world FER remains challenging (pose, lighting, occlusion)

SLIDE 14: Future Work
- Potential improvements:
  * Collect more data for minority classes (fear, disgust)
  * Try more advanced architectures (EfficientNet, Vision Transformers)
  * Implement class balancing techniques (oversampling, focal loss)
  * Add face detection preprocessing (MTCNN)
  * Real-time video emotion recognition
  * Cross-dataset evaluation for generalization

SLIDE 15: Conclusion
- Successfully compared traditional ML vs deep learning for FER
- Transfer learning achieved best results
- Demonstrated model interpretability with Grad-CAM
- Identified class imbalance as key challenge
- Provided foundation for future improvements
- Thank you slide with Q&A invitation

================================================================================
DESIGN GUIDELINES
================================================================================
- Color scheme: Professional blues and grays, with accent colors for emphasis
- Font: Clean sans-serif (e.g., Open Sans, Roboto, or Montserrat)
- Use icons and visuals to represent concepts
- Minimize text, maximize visuals
- Include slide numbers
- Consistent layout across slides
- Use animations sparingly (only for emphasis)
- Include the university/course logo if available

================================================================================
VISUAL ELEMENTS TO INCLUDE
================================================================================
1. Sample face images from each emotion class (grid layout)
2. Class distribution bar chart or pie chart
3. Architecture diagrams for CNN and ResNet
4. Training curves (loss/accuracy vs epochs)
5. Confusion matrix heatmaps
6. Grad-CAM visualization examples (original → heatmap → overlay)
7. Model comparison bar chart
8. Flowchart of methodology

================================================================================
TONE & STYLE
================================================================================
- Academic but accessible
- Data-driven with clear metrics
- Visual-heavy, text-light
- Suitable for 10-15 minute presentation
- Engaging for both technical and non-technical audience
- Professional and polished

================================================================================
NOTES
================================================================================
- Leave placeholders for actual result numbers where I wrote XX.X%
- The baseline result of 82.1% is confirmed
- Emphasize the comparative nature of the study
- Highlight both successes and challenges honestly
