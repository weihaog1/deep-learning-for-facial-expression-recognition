{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Transfer Learning with ResNet18\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this notebook, we'll use **transfer learning** to leverage a model pretrained on ImageNet.\n",
    "\n",
    "### What is Transfer Learning?\n",
    "\n",
    "Instead of training from scratch, we:\n",
    "1. Start with a model already trained on a large dataset (ImageNet: 1.2M images, 1000 classes)\n",
    "2. Replace the final classification layer for our 7 emotions\n",
    "3. Fine-tune on our specific dataset\n",
    "\n",
    "### Why Transfer Learning?\n",
    "\n",
    "| Benefit | Explanation |\n",
    "|---------|-------------|\n",
    "| **Better features** | Pretrained models learned robust features from millions of images |\n",
    "| **Faster training** | Only need to fine-tune, not learn from scratch |\n",
    "| **Less data needed** | Features already generalize well |\n",
    "| **Higher accuracy** | Usually outperforms training from scratch |\n",
    "\n",
    "### Our Strategy:\n",
    "\n",
    "**Two-phase training:**\n",
    "1. **Phase 1**: Freeze backbone, train only classifier (fast)\n",
    "2. **Phase 2**: Unfreeze, fine-tune entire network with low learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "IMG_SIZE = 224\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 25\n",
    "LEARNING_RATE = 0.001      # For phase 1 (classifier only)\n",
    "FINE_TUNE_LR = 0.0001      # For phase 2 (full network)\n",
    "PATIENCE = 5\n",
    "\n",
    "EMOTION_CLASSES = [\"anger\", \"disgust\", \"fear\", \"happiness\", \"neutral\", \"sadness\", \"surprise\"]\n",
    "NUM_CLASSES = len(EMOTION_CLASSES)\n",
    "IDX_TO_EMOTION = {i: e for i, e in enumerate(EMOTION_CLASSES)}\n",
    "\n",
    "print(\"Configuration loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed data\n",
    "with open('processed_data.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "train_df = data['train_df']\n",
    "val_df = data['val_df']\n",
    "test_df = data['test_df']\n",
    "\n",
    "print(f\"Training: {len(train_df)}, Validation: {len(val_df)}, Test: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset and DataLoaders (same as before)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "])\n",
    "\n",
    "class FacialExpressionDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.data = dataframe.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        image = Image.open(row['image_path']).convert('RGB')\n",
    "        label = row['label']\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "train_dataset = FacialExpressionDataset(train_df, transform=train_transform)\n",
    "val_dataset = FacialExpressionDataset(val_df, transform=test_transform)\n",
    "test_dataset = FacialExpressionDataset(test_df, transform=test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "print(\"Data loaders created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Understanding ResNet18\n",
    "\n",
    "### What is ResNet?\n",
    "\n",
    "**ResNet (Residual Network)** introduced skip connections that allow training very deep networks.\n",
    "\n",
    "```\n",
    "Standard block:    Input → Conv → Conv → Output\n",
    "Residual block:    Input → Conv → Conv → Add(Input) → Output\n",
    "                            ↑______________↓\n",
    "                           (skip connection)\n",
    "```\n",
    "\n",
    "### Why Skip Connections Help:\n",
    "- **Gradient flow**: Gradients can flow directly through skip connections\n",
    "- **Identity mapping**: If a layer isn't needed, it can learn to be identity\n",
    "- **Deeper networks**: Enables training 100+ layer networks\n",
    "\n",
    "### ResNet18 Architecture:\n",
    "```\n",
    "conv1 (7x7, 64 channels)\n",
    "    ↓\n",
    "maxpool\n",
    "    ↓\n",
    "layer1 (2 residual blocks, 64 channels)\n",
    "    ↓\n",
    "layer2 (2 residual blocks, 128 channels)\n",
    "    ↓\n",
    "layer3 (2 residual blocks, 256 channels)\n",
    "    ↓\n",
    "layer4 (2 residual blocks, 512 channels)\n",
    "    ↓\n",
    "avgpool (global average pooling)\n",
    "    ↓\n",
    "fc (512 → 1000 classes)  ← We replace this!\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the pretrained ResNet18\n",
    "resnet_demo = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "\n",
    "print(\"ResNet18 Architecture:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Show each main component\n",
    "for name, module in resnet_demo.named_children():\n",
    "    if isinstance(module, nn.Sequential):\n",
    "        print(f\"{name}: {len(module)} blocks\")\n",
    "    else:\n",
    "        print(f\"{name}: {module.__class__.__name__}\")\n",
    "\n",
    "print(f\"\\nOriginal fc layer: {resnet_demo.fc}\")\n",
    "print(f\"Input features to fc: {resnet_demo.fc.in_features}\")\n",
    "print(f\"Output classes: {resnet_demo.fc.out_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create Transfer Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransferLearningModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Transfer learning model using ResNet18 pretrained on ImageNet.\n",
    "    \n",
    "    Strategy:\n",
    "    1. Load pretrained ResNet18 weights\n",
    "    2. Replace final fc layer with our classifier\n",
    "    3. Optionally freeze backbone for initial training\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=NUM_CLASSES, freeze_backbone=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Load pretrained ResNet18\n",
    "        # weights=IMAGENET1K_V1 loads ImageNet pretrained weights\n",
    "        self.backbone = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "        \n",
    "        # Freeze backbone if specified\n",
    "        # This prevents updating pretrained weights initially\n",
    "        if freeze_backbone:\n",
    "            for param in self.backbone.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        # Replace the final fully connected layer\n",
    "        # Original: Linear(512, 1000) for ImageNet\n",
    "        # New: Dropout + Linear(512, 7) for our emotions\n",
    "        num_features = self.backbone.fc.in_features  # 512\n",
    "        self.backbone.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(num_features, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "    \n",
    "    def unfreeze_backbone(self):\n",
    "        \"\"\"\n",
    "        Unfreeze all backbone layers for fine-tuning.\n",
    "        \n",
    "        Call this after phase 1 training to enable\n",
    "        updating all weights with a lower learning rate.\n",
    "        \"\"\"\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = True\n",
    "        print(\"Backbone unfrozen - all layers now trainable\")\n",
    "    \n",
    "    def get_feature_maps(self, x):\n",
    "        \"\"\"Get feature maps from last conv layer (for Grad-CAM).\"\"\"\n",
    "        x = self.backbone.conv1(x)\n",
    "        x = self.backbone.bn1(x)\n",
    "        x = self.backbone.relu(x)\n",
    "        x = self.backbone.maxpool(x)\n",
    "        x = self.backbone.layer1(x)\n",
    "        x = self.backbone.layer2(x)\n",
    "        x = self.backbone.layer3(x)\n",
    "        x = self.backbone.layer4(x)\n",
    "        return x\n",
    "\n",
    "print(\"TransferLearningModel defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model with frozen backbone\n",
    "model = TransferLearningModel(num_classes=NUM_CLASSES, freeze_backbone=True)\n",
    "model = model.to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "frozen_params = total_params - trainable_params\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MODEL SUMMARY (Phase 1: Backbone Frozen)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,} ({100*trainable_params/total_params:.1f}%)\")\n",
    "print(f\"Frozen parameters: {frozen_params:,} ({100*frozen_params/total_params:.1f}%)\")\n",
    "\n",
    "# This shows that most parameters are frozen!\n",
    "# Only the new fc layer is trainable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=\"Training\", leave=False)\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}', 'acc': f'{100.*correct/total:.2f}%'})\n",
    "    \n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=PATIENCE, min_delta=0.001):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = float('inf')\n",
    "        self.should_stop = False\n",
    "    \n",
    "    def __call__(self, val_loss):\n",
    "        if val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            return True\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.should_stop = True\n",
    "            return False\n",
    "\n",
    "print(\"Training functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Phase 1 - Train Classifier Only\n",
    "\n",
    "In Phase 1:\n",
    "- Backbone is **frozen** (pretrained weights preserved)\n",
    "- Only train the new classification layer\n",
    "- Use normal learning rate\n",
    "- This is fast because we only update ~4000 parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 1 setup\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "early_stopping = EarlyStopping(patience=3)  # Shorter patience for phase 1\n",
    "\n",
    "phase1_epochs = NUM_EPOCHS // 2\n",
    "history_phase1 = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PHASE 1: Training Classifier (Backbone Frozen)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "print(f\"Training for up to {phase1_epochs} epochs...\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "start_time = time.time()\n",
    "best_model_state = None\n",
    "\n",
    "for epoch in range(phase1_epochs):\n",
    "    print(f\"\\nPhase 1 - Epoch {epoch + 1}/{phase1_epochs}\")\n",
    "    \n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    history_phase1['train_loss'].append(train_loss)\n",
    "    history_phase1['train_acc'].append(train_acc)\n",
    "    history_phase1['val_loss'].append(val_loss)\n",
    "    history_phase1['val_acc'].append(val_acc)\n",
    "    \n",
    "    print(f\"  Train: loss={train_loss:.4f}, acc={train_acc:.4f}\")\n",
    "    print(f\"  Val:   loss={val_loss:.4f}, acc={val_acc:.4f}\")\n",
    "    \n",
    "    is_best = early_stopping(val_loss)\n",
    "    if is_best:\n",
    "        print(\"  ✓ Best model so far!\")\n",
    "        best_model_state = model.state_dict().copy()\n",
    "    \n",
    "    if early_stopping.should_stop:\n",
    "        print(\"\\nEarly stopping phase 1\")\n",
    "        break\n",
    "\n",
    "phase1_time = time.time() - start_time\n",
    "print(f\"\\nPhase 1 completed in {phase1_time/60:.1f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Phase 2 - Fine-tune Entire Network\n",
    "\n",
    "In Phase 2:\n",
    "- **Unfreeze** the backbone\n",
    "- Use a **lower learning rate** (10x smaller)\n",
    "- Fine-tune all layers together\n",
    "- The pretrained features get slightly adjusted for our task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model from phase 1\n",
    "model.load_state_dict(best_model_state)\n",
    "\n",
    "# Unfreeze backbone\n",
    "model.unfreeze_backbone()\n",
    "\n",
    "# Phase 2 setup with lower learning rate\n",
    "optimizer = optim.Adam(model.parameters(), lr=FINE_TUNE_LR)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "early_stopping = EarlyStopping(patience=PATIENCE)\n",
    "\n",
    "phase2_epochs = NUM_EPOCHS // 2\n",
    "history_phase2 = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PHASE 2: Fine-tuning Entire Network\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Learning rate: {FINE_TUNE_LR} (10x lower than phase 1)\")\n",
    "print(f\"Training for up to {phase2_epochs} epochs...\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "start_time = time.time()\n",
    "best_epoch = 0\n",
    "\n",
    "for epoch in range(phase2_epochs):\n",
    "    print(f\"\\nPhase 2 - Epoch {epoch + 1}/{phase2_epochs}\")\n",
    "    \n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    history_phase2['train_loss'].append(train_loss)\n",
    "    history_phase2['train_acc'].append(train_acc)\n",
    "    history_phase2['val_loss'].append(val_loss)\n",
    "    history_phase2['val_acc'].append(val_acc)\n",
    "    \n",
    "    print(f\"  Train: loss={train_loss:.4f}, acc={train_acc:.4f}\")\n",
    "    print(f\"  Val:   loss={val_loss:.4f}, acc={val_acc:.4f}\")\n",
    "    \n",
    "    is_best = early_stopping(val_loss)\n",
    "    if is_best:\n",
    "        print(\"  ✓ New best model!\")\n",
    "        best_model_state = model.state_dict().copy()\n",
    "        best_epoch = epoch\n",
    "    \n",
    "    if early_stopping.should_stop:\n",
    "        print(\"\\nEarly stopping phase 2\")\n",
    "        break\n",
    "\n",
    "phase2_time = time.time() - start_time\n",
    "print(f\"\\nPhase 2 completed in {phase2_time/60:.1f} minutes\")\n",
    "\n",
    "# Load final best model\n",
    "model.load_state_dict(best_model_state)\n",
    "print(f\"Loaded best model from phase 2 epoch {best_epoch + 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Visualize Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine histories\n",
    "all_train_loss = history_phase1['train_loss'] + history_phase2['train_loss']\n",
    "all_val_loss = history_phase1['val_loss'] + history_phase2['val_loss']\n",
    "all_train_acc = history_phase1['train_acc'] + history_phase2['train_acc']\n",
    "all_val_acc = history_phase1['val_acc'] + history_phase2['val_acc']\n",
    "\n",
    "phase1_end = len(history_phase1['train_loss'])\n",
    "epochs = range(1, len(all_train_loss) + 1)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss plot\n",
    "axes[0].plot(epochs, all_train_loss, 'b-', label='Training')\n",
    "axes[0].plot(epochs, all_val_loss, 'r-', label='Validation')\n",
    "axes[0].axvline(phase1_end, color='green', linestyle='--', label='Phase 1 → 2', alpha=0.7)\n",
    "axes[0].fill_between(range(1, phase1_end + 1), 0, max(all_train_loss), \n",
    "                     alpha=0.1, color='blue', label='Phase 1 (frozen)')\n",
    "axes[0].fill_between(range(phase1_end, len(epochs) + 1), 0, max(all_train_loss), \n",
    "                     alpha=0.1, color='orange', label='Phase 2 (fine-tune)')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training and Validation Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy plot\n",
    "axes[1].plot(epochs, all_train_acc, 'b-', label='Training')\n",
    "axes[1].plot(epochs, all_val_acc, 'r-', label='Validation')\n",
    "axes[1].axvline(phase1_end, color='green', linestyle='--', label='Phase 1 → 2', alpha=0.7)\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].set_title('Training and Validation Accuracy')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Transfer Learning Training History (Two-Phase)', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test evaluation\n",
    "test_loss, test_acc = validate(model, test_loader, criterion, device)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"FINAL RESULTS (Transfer Learning)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTest Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions and detailed metrics\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = outputs.max(1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=EMOTION_CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=EMOTION_CLASSES, yticklabels=EMOTION_CLASSES, ax=axes[0])\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('True')\n",
    "axes[0].set_title('Confusion Matrix (Counts)')\n",
    "\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.1%', cmap='Blues',\n",
    "            xticklabels=EMOTION_CLASSES, yticklabels=EMOTION_CLASSES, ax=axes[1])\n",
    "axes[1].set_xlabel('Predicted')\n",
    "axes[1].set_ylabel('True')\n",
    "axes[1].set_title('Confusion Matrix (Normalized)')\n",
    "\n",
    "plt.suptitle('Transfer Learning (ResNet18) Results', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Save Model and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'test_acc': test_acc,\n",
    "    'test_loss': test_loss\n",
    "}, 'transfer_learning_best.pth')\n",
    "\n",
    "print(\"Model saved!\")\n",
    "\n",
    "# Save results for comparison\n",
    "transfer_results = {\n",
    "    'model_name': 'Transfer Learning (ResNet18)',\n",
    "    'test_accuracy': test_acc,\n",
    "    'test_loss': test_loss,\n",
    "    'phase1_time_minutes': phase1_time / 60,\n",
    "    'phase2_time_minutes': phase2_time / 60,\n",
    "    'confusion_matrix': cm.tolist()\n",
    "}\n",
    "\n",
    "with open('transfer_learning_results.pkl', 'wb') as f:\n",
    "    pickle.dump(transfer_results, f)\n",
    "\n",
    "print(\"Results saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What We Learned:\n",
    "\n",
    "1. **Transfer Learning** leverages pretrained knowledge from ImageNet\n",
    "2. **Two-phase training** is effective: freeze first, then fine-tune\n",
    "3. **Lower learning rate** for fine-tuning prevents destroying pretrained features\n",
    "\n",
    "### Results Comparison:\n",
    "\n",
    "| Model | Test Accuracy |\n",
    "|-------|---------------|\n",
    "| HOG + SVM | ~XX% |\n",
    "| Custom CNN | ~XX% |\n",
    "| ResNet18 (Transfer) | ~XX% |\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "- **Pretrained models** often outperform training from scratch\n",
    "- **Fine-tuning** adapts general features to your specific task\n",
    "- **ImageNet features** transfer well to facial expression recognition\n",
    "\n",
    "### Next Steps:\n",
    "- **Notebook 5**: Compare all models side by side\n",
    "- **Notebook 6**: Use Grad-CAM to visualize what the models learn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
